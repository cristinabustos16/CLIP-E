# CLIP-E 
This github contains the trained models described in our paper "On the use of Vision-Language models for Visual Sentiment Analysis: a study on CLIP" published in the International Conference on Affective Computing + Intelligent Interaction (ACII 2023)
